{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import division\n",
    "# __future__ 파이썬2.x 에서 몇몇 기능들을 파이썬3.x 와 같이 사용 가능하게 만들어 주는 모듈이다.\n",
    "\n",
    "import argparse\n",
    "import io\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "# os.path.abspath(path) - 현재 경로를 prefix로 하여 입력받은 경로를 절\n",
    "# 대경로로 바꿔서 반환합니다\n",
    "# os.path.dirname(path) - 입력받은 파일/ 디렉터리의 경로를 반환한다\n",
    "# Default data paths.\n",
    "DEFAULT_LABEL_CSV = os.path.join(SCRIPT_PATH, '../image-data/labels-map.csv')\n",
    "DEFAULT_LABEL_FILE = os.path.join(SCRIPT_PATH,\n",
    "                                  '../labels/2350-common-hangul.txt')\n",
    "#os.path.join(path) - 해당 os형식에 맞도록 입력 받은 경로를 연결합니다\n",
    "DEFAULT_OUTPUT_DIR = os.path.join(SCRIPT_PATH, '../tfrecords-output')\n",
    "DEFAULT_NUM_SHARDS_TRAIN = 1\n",
    "DEFAULT_NUM_SHARDS_TEST = 1\n",
    "\n",
    "#FRecord 파일 생성은 tf.train.Example에 \n",
    "#Feature를 딕셔너리 형태로 정의한 후에, \n",
    "#tf.train.Example 객체를 TFRecord 파일 포맷 \n",
    "#Writer인 tf.python_io.TFRecordWriter를 통해서 파일로 저장하면 된다.\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "# 메세지 타입 \n",
    "#tf.train.BytesList – string, byte값으로부터 mapping\n",
    "#tf.train.FloatList –  float (float32), double (float64) 값으로부터 mapping\n",
    "#tf.train.Int64List – bool, enum, int32, uint32, int64, uint64 값으로부터 mapping\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "class TFRecordsConverter(object):\n",
    "    \"\"\"Class that handles converting images to TFRecords.\"\"\"\n",
    "\n",
    "    def __init__(self, labels_csv, label_file, output_dir,\n",
    "                 num_shards_train, num_shards_test):\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "        self.num_shards_train = num_shards_train\n",
    "        self.num_shards_test = num_shards_test\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        # Get lists of images and labels.\n",
    "        self.filenames, self.labels = \\\n",
    "            self.process_image_labels(labels_csv, label_file)\n",
    "\n",
    "        # Counter for total number of images processed.\n",
    "        self.counter = 0\n",
    "\n",
    "    def process_image_labels(self, labels_csv, label_file):\n",
    "        \"\"\"This will constuct two shuffled lists for images and labels.\n",
    "        The index of each image in the images list will have the corresponding\n",
    "        label at the same index in the labels list.\n",
    "        \"\"\"\n",
    "        labels_csv = io.open(labels_csv, 'r', encoding='utf-8')\n",
    "        labels_file = io.open(label_file, 'r',\n",
    "                              encoding='utf-8').read().splitlines()\n",
    "\n",
    "        # Map characters to indices.\n",
    "        label_dict = {}\n",
    "        count = 0\n",
    "        for label in labels_file:\n",
    "            label_dict[label] = count\n",
    "            count += 1\n",
    "\n",
    "        # Build the lists.\n",
    "        images = []\n",
    "        labels = []\n",
    "        for row in labels_csv:\n",
    "            file, label = row.strip().split(',')\n",
    "            images.append(file)\n",
    "            labels.append(label_dict[label])\n",
    "\n",
    "        # Randomize the order of all the images/labels.\n",
    "        shuffled_indices = list(range(len(images)))\n",
    "        random.seed(12121)\n",
    "        random.shuffle(shuffled_indices)\n",
    "        filenames = [images[i] for i in shuffled_indices]\n",
    "        labels = [labels[i] for i in shuffled_indices]\n",
    "\n",
    "        return filenames, labels\n",
    "\n",
    "    def write_tfrecords_file(self, output_path, indices):\n",
    "        \"\"\"Writes out TFRecords file.\"\"\"\n",
    "        writer = tf.python_io.TFRecordWriter(output_path)\n",
    "        for i in indices:\n",
    "            filename = self.filenames[i]\n",
    "            label = self.labels[i]\n",
    "            with tf.gfile.GFile(filename, 'rb') as f:\n",
    "                im_data = f.read()\n",
    "\n",
    "            # Example is a data format that contains a key-value store, where\n",
    "            # each key maps to a Feature message. In this case, each Example\n",
    "            # contains two features. One will be a ByteList for the raw image\n",
    "            # data and the other will be an Int64List containing the index of\n",
    "            # the corresponding label in the labels list from the file.\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/class/label': _int64_feature(label),\n",
    "                'image/encoded': _bytes_feature(tf.compat.as_bytes(im_data))}))\n",
    "            writer.write(example.SerializeToString())\n",
    "            self.counter += 1\n",
    "            if not self.counter % 1000:\n",
    "                print('Processed {} images...'.format(self.counter))\n",
    "        writer.close()\n",
    "\n",
    "    def convert(self):\n",
    "        \"\"\"This function will drive the conversion to TFRecords.\n",
    "        Here, we partition the data into a training and testing set, then\n",
    "        divide each data set into the specified number of TFRecords shards.\n",
    "        \"\"\"\n",
    "\n",
    "        num_files_total = len(self.filenames)\n",
    "\n",
    "        # Allocate about 15 percent of images to testing\n",
    "        num_files_test = int(num_files_total * .15)\n",
    "\n",
    "        # About 85 percent will be for training.\n",
    "        num_files_train = num_files_total - num_files_test\n",
    "\n",
    "        print('Processing training set TFRecords...')\n",
    "\n",
    "        files_per_shard = int(math.ceil(num_files_train /\n",
    "                                        self.num_shards_train))\n",
    "        start = 0\n",
    "        for i in range(1, self.num_shards_train):\n",
    "            shard_path = os.path.join(self.output_dir,\n",
    "                                      'train-{}.tfrecords'.format(str(i)))\n",
    "            # Get a subset of indices to get only a subset of images/labels for\n",
    "            # the current shard file.\n",
    "            file_indices = np.arange(start, start+files_per_shard, dtype=int)\n",
    "            start = start + files_per_shard\n",
    "            self.write_tfrecords_file(shard_path, file_indices)\n",
    "\n",
    "        # The remaining images will go in the final shard.\n",
    "        file_indices = np.arange(start, num_files_train, dtype=int)\n",
    "        final_shard_path = os.path.join(self.output_dir,\n",
    "                                        'train-{}.tfrecords'.format(\n",
    "                                            str(self.num_shards_train)))\n",
    "        self.write_tfrecords_file(final_shard_path, file_indices)\n",
    "\n",
    "        print('Processing testing set TFRecords...')\n",
    "\n",
    "        files_per_shard = math.ceil(num_files_test / self.num_shards_test)\n",
    "        start = num_files_train\n",
    "        for i in range(1, self.num_shards_test):\n",
    "            shard_path = os.path.join(self.output_dir,\n",
    "                                      'test-{}.tfrecords'.format(str(i)))\n",
    "            file_indices = np.arange(start, start+files_per_shard, dtype=int)\n",
    "            start = start + files_per_shard\n",
    "            self.write_tfrecords_file(shard_path, file_indices)\n",
    "\n",
    "        # The remaining images will go in the final shard.\n",
    "        file_indices = np.arange(start, num_files_total, dtype=int)\n",
    "        final_shard_path = os.path.join(self.output_dir,\n",
    "                                        'test-{}.tfrecords'.format(\n",
    "                                            str(self.num_shards_test)))\n",
    "        self.write_tfrecords_file(final_shard_path, file_indices)\n",
    "\n",
    "        print('\\nProcessed {} total images...'.format(self.counter))\n",
    "        print('Number of training examples: {}'.format(num_files_train))\n",
    "        print('Number of testing examples: {}'.format(num_files_test))\n",
    "        print('TFRecords files saved to {}'.format(self.output_dir))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--image-label-csv', type=str, dest='labels_csv',\n",
    "                        default=DEFAULT_LABEL_CSV,\n",
    "                        help='File containing image paths and corresponding '\n",
    "                             'labels.')\n",
    "    parser.add_argument('--label-file', type=str, dest='label_file',\n",
    "                        default=DEFAULT_LABEL_FILE,\n",
    "                        help='File containing newline delimited labels.')\n",
    "    parser.add_argument('--output-dir', type=str, dest='output_dir',\n",
    "                        default=DEFAULT_OUTPUT_DIR,\n",
    "                        help='Output directory to store TFRecords files.')\n",
    "    parser.add_argument('--num-shards-train', type=int,\n",
    "                        dest='num_shards_train',\n",
    "                        default=DEFAULT_NUM_SHARDS_TRAIN,\n",
    "                        help='Number of shards to divide training set '\n",
    "                             'TFRecords into.')\n",
    "    parser.add_argument('--num-shards-test', type=int,\n",
    "                        dest='num_shards_test',\n",
    "                        default=DEFAULT_NUM_SHARDS_TEST,\n",
    "                        help='Number of shards to divide testing set '\n",
    "                             'TFRecords into.')\n",
    "    args = parser.parse_args()\n",
    "    converter = TFRecordsConverter(args.labels_csv,\n",
    "                                   args.label_file,\n",
    "                                   args.output_dir,\n",
    "                                   args.num_shards_train,\n",
    "                                   args.num_shards_test)\n",
    "    converter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
