{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-5f147f0732d7>:14: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-5f147f0732d7>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171D8107F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "n_inputs=3 # 입력데이터\n",
    "n_neurons = 5 # 셀의 가중치 사이즈\n",
    "tf.reset_default_graph() # 그라프 초기화(변수 생성)\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs]) # 4x3 말단데이터 개수가 3\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs]) # 4x3\n",
    "#[0,1,2] 사이즈가 하나의 셀로 입력\n",
    "# FFNN(feed forweard neural network)\n",
    "\n",
    "# 가중치 사이즈 => 특성을 찾아내는  것\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "# static_rnn : rnn network : 4개의 셀이 자동으로 연결된면서 메모리 확보\n",
    "output_seqs,states = tf.contrib.rnn.static_rnn(basic_cell,[X0,X1],dtype=tf.float32) # 2x4x3 , 배치사이즈 * 셀 수 * 뉴런 수\n",
    "\n",
    "Y0,Y1 = output_seqs\n",
    "\n",
    "# 출력, 다음셀로 전달되는 값 : 마지막 states값(수평으로 셀을 연결)\n",
    "init = tf.global_variables_initializer()\n",
    "X0_batch = np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]]) # 4x3\n",
    "X1_batch = np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처음 데이터 특성 : \n",
      "[[-0.33641216  0.3341674   0.30749053 -0.7726948   0.7692158 ]\n",
      " [-0.7707651   0.16922277  0.94614005 -0.9998492   0.922941  ]\n",
      " [-0.9347026  -0.00577932  0.9971119  -0.9999998   0.9756778 ]\n",
      " [ 0.1724769  -0.7828837   0.9998124  -0.9999937  -0.9973935 ]] \n",
      "차수 : (4, 5) \n",
      "두번째 데이터 특성 : \n",
      "[[-0.95321894 -0.8626379   0.999878   -1.          0.89323056]\n",
      " [-0.01320682 -0.620482    0.51450783 -0.52114797  0.489258  ]\n",
      " [-0.72890836 -0.8911757   0.99628913 -0.9999986   0.5845853 ]\n",
      " [-0.40252233 -0.8914003   0.45425022 -0.98890555 -0.9148378 ]] \n",
      "차수 : (4, 5) \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0,Y1], feed_dict={X0:X0_batch, X1:X1_batch})\n",
    "    \n",
    "    print('처음 데이터 특성 : \\n{} \\n차수 : {} '.format(Y0_val, Y0_val.shape))\n",
    "    print('두번째 데이터 특성 : \\n{} \\n차수 : {} '.format(Y1_val, Y1_val.shape))\n",
    "    # 4x3 => 4x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "? 셀이 가지고 있는 가중치 사이즈 : 3x5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-135e417bb638>:24: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB113608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB113608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB113608>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB113608>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-3-135e417bb638>:31: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171D8107F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171D8107F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171D8107F88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171D8107F88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # 그라프 초기화(변수 생성)\n",
    "n_steps = 28 # 셀수 \n",
    "n_inputs = 28 # 셀당 인풋사이즈\n",
    "n_neurons = 150 # 뉴런\n",
    "n_outputs = 10 # 확률사이즈\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 3차원으로 데이터를 받아오기때문에\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # ? x 28x 28\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# FFNN\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons) #150\n",
    "# 데이터가 3차원으로 입력됨\n",
    "# 2차원이 셀수\n",
    "# 셀 : 28개\n",
    "# state 마지막셀의 수평으로 전달되는 값\n",
    "# state 마지막셀의 output과 같다.\n",
    "# 28개의 셀이 있는데 마지막 한개의 output을 사용 => many to one\n",
    "# 감정분류 -> 분류\n",
    "# state의 차수 : 150x150\n",
    "# output의 차수 : latent time 지연시간을 통해 계산된 셀의 \n",
    "# 모든 값을 결합 출력 150x28x150\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X,dtype=tf.float32)\n",
    "\n",
    "# 150개의 특징중에 10개만 추출\n",
    "# dense 입력차수, 출력차수만 지정하면 자동으로 바이어스를 생성\n",
    "# 가중치 공간을 확보해서 \n",
    "# 150x150, => 150x10\n",
    "# dense.의 가중치 사이즈 = 150x10\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "# 분류를 위한 미분이 가능한 식으로 바뀜\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy) # 배치사이즈  => 평균을 통해서 loss를 구한다.\n",
    "\n",
    "# momentum _ propgrad\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "# 양쪽에서 큰놈으로 \n",
    "# 가장큰값\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-f30766f3c944>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')\n",
    "# 원래이미지 모양으로 학습한다.\n",
    "X_test = mnist.test.images.reshape((-1,n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy :  0.93333334 Test accyract :  0.922\n",
      "1 Train accuracy :  0.97333336 Test accyract :  0.9456\n",
      "2 Train accuracy :  0.96 Test accyract :  0.9505\n",
      "3 Train accuracy :  0.98 Test accyract :  0.9561\n",
      "4 Train accuracy :  0.9266667 Test accyract :  0.9649\n",
      "5 Train accuracy :  0.9866667 Test accyract :  0.9545\n",
      "6 Train accuracy :  0.97333336 Test accyract :  0.968\n",
      "7 Train accuracy :  0.96666664 Test accyract :  0.96\n",
      "8 Train accuracy :  0.96666664 Test accyract :  0.9732\n",
      "9 Train accuracy :  0.9866667 Test accyract :  0.9716\n"
     ]
    }
   ],
   "source": [
    "# n_epochs= 100\n",
    "n_epochs= 10\n",
    "batch_size = 150\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in  range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): # 60000/150 을 100번 반복해서 돈다.\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            # 이미지 사이즈로 생성\n",
    "            X_batch = X_batch.reshape((-1,n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "        print(epoch, 'Train accuracy : ', acc_train, 'Test accyract : ',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi rnn cell\n",
    "# 오타 찾아라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BasicRNNCell : 기본데이터가 입력\n",
    "# # MultiRNNCell : 수직으로 레이어 구성 : 수직우로 셀이 구성\n",
    "# # dynamic_rnn : 모델\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.reset_default_graph() # 그라프 초기화(변수 생성)\n",
    "\n",
    "# n_steps = 28\n",
    "# n_inputs = 28\n",
    "# n_outputs = 10\n",
    "# learning_rate = 0.001\n",
    "# X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "# y = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "# n_neurons = 100\n",
    "# n_layers = 3 # 3개의 멀티 레이어 : 3개의 셀을 생성\n",
    "# layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu) for layer in range(n_layers)]\n",
    "\n",
    "# # 3개를 조합해서 MultiRNNCell을 만든다.\n",
    "# multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "\n",
    "                                \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dynamic_rnn : 셀로 입력 되는 데이터의 개수에 맞추어서 셀을 구성\n",
    "# # 나는 학교에 간다. ->  static_rnn 동일한 사이즈 : 큰것 기준, 작은것은 padding\n",
    "# # 입력사이즈 변동 => 가중치 조절 => 나가는 특징은 일치(neural수가 같다.)\n",
    "# # 3층 셀이 28개가 조성 : 고정 사이즈\n",
    "# outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "# # states가 몇개가 발생하는가\n",
    "# # 3x150x100\n",
    "# states_concat = tf.concat(axis = 1, values=states) # 150x300\n",
    "# logits = tf.layers.dense(states_concat, n_outputs) # 가중치 :  300x10 => 150x10 확률값\n",
    "# # 원핫인코딩 * log(예측값)\n",
    "# xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=logits)\n",
    "\n",
    "# loss = rf.reduce.mean(xectropy)\n",
    "\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# training_op = optimizer.minimize(loss)\n",
    "# coreect =tf.nn.in_top_k(logits, y,1)\n",
    "# accuracy = tf.reduce_mean(tf.cats(correct, tf.float32))\n",
    "# init = tf.global_varibles_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs= 100\n",
    "# batch_size = 150\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "#     for epoch in  range(n_epochs):\n",
    "#         for iteration in range(mnist.train.num_examples // batch_size): # 60000/150 을 100번 반복해서 돈다.\n",
    "#             X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "#             # 이미지 사이즈로 생성\n",
    "#             X_batch = X_batch.reshape((-1,n_steps, n_inputs))\n",
    "#             sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "#         acc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "#         acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "#         print(epoch, 'Train accuracy : ', acc_train, 'Test accyract : ',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-2720fdc25240>:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "#  MUltiRNNCELll 을 할것이다 >> 3단계로 구성되어있다  (basic rnncell, multi rnncell, dynamic_rnn 으로 구성)\n",
    "#BasicRNNCell : 기본데이터가 입력되는 곳은 basicrnncell 이다!! \n",
    "# MultiRNNCell : 수직으로 레이어 구성( 아까는 이거 없었음 )  수평으로 구성되어있었는데 이번에는 수직으로도 구성 >> 밑에보면 3개로\n",
    "#            >>> multirnncell 로 의해서 수직으로 셀이 구성 \n",
    "# dynamic_rnn : 이것이 모델이다 \n",
    "tf.reset_default_graph()  # \n",
    "n_steps= 28\n",
    "n_inputs=28\n",
    "n_outputs=10\n",
    "learning_rate = 0.001\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "n_neurons=100\n",
    "n_layers=3  # 3개의 멀티레이어 \n",
    "layers=[tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu) for layer in range(n_layers)]  # basicrnncell 은  3개만들어짐 for 문통해 확인가능>>> 3개의 셀 생성\n",
    "\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers) # 3개의 셀을 조합해서 multirnncell 을 만든다 ( 셀이 3층으로 구성되어있다 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8A8788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8A8788>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8A8788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8A8788>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8A8508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8A8508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8A8508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8A8508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8388>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8388>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8B48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB8B8B48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171DB1C45C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171DB1C45C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171DB1C45C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000171DB1C45C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# 이번엔 dynamic_rnn 이다  : 셀로입력되는 데이터의 개수에 맞추어서 셀을 구성할 수 있다 \n",
    "#ex )  나는 학교에 간다. ( 2글자 + 3글자+2글자 --> 사이즈가 다르다 -> \n",
    "#  사이즈가 다르면 static_rnn 에서는  동일한사이즈로 맞췄다.-> 큰것을 기준으로 작은 것을 padding 했었다 >> 결과가 안좋게 나오기떄문에 dynamic_rnn 을 쓴다 \n",
    "#  dynamic_rnn 은 사이즈가 다르면 다른대로 상관하지 않는다. (입력사이즈를 변동>>> 가중치를 조절한다 >> 나가는 특징은 일치함 = neural 수는 같다 ) \n",
    "\n",
    "# 3층 셀이 28개가 조성이 된다 :: 고정사이즈이다  \n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "# states 가 몇개가 발생하는가?? \n",
    "# 3x 150x 100  ( 층이 3층이므로 3층, 배치사이즈가 150이니까 150,   150x100 인데 3층이니까 3이붙는것이다 )\n",
    "\n",
    "states_concat = tf.concat(axis=1, values= states)  # concat 이 열방향으로 하게됨 (axis=1 에 의해서) >>> 150x300 이 된다  \n",
    "logits= tf.layers.dense(states_concat, n_outputs)  # dense : 입력차수와 출력차수를 넣어주면 가중치 사이즈를 자기가 만든다 \n",
    "                                            #150x300 이 들어오고,  출력차수가 10이니까 가중치는 300 x10 이 됨   \n",
    "\n",
    "    #가중치계산해서 나온결과는  150( 미니배치사이즈 ) x10 ( 확률적으로 나타나는 10개의 특징=확률값)\n",
    "        # 원핫인코딩 x log( 에측값)  ? ? \n",
    "    \n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,  logits=logits)\n",
    "loss= tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits,y,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy :  0.9533333 Test accyract :  0.9469\n",
      "1 Train accuracy :  0.9533333 Test accyract :  0.962\n",
      "2 Train accuracy :  0.97333336 Test accyract :  0.9686\n",
      "3 Train accuracy :  0.96 Test accyract :  0.969\n",
      "4 Train accuracy :  0.98 Test accyract :  0.9779\n",
      "5 Train accuracy :  0.99333334 Test accyract :  0.978\n",
      "6 Train accuracy :  0.9866667 Test accyract :  0.9784\n",
      "7 Train accuracy :  0.97333336 Test accyract :  0.9831\n",
      "8 Train accuracy :  0.99333334 Test accyract :  0.9828\n",
      "9 Train accuracy :  0.99333334 Test accyract :  0.9832\n"
     ]
    }
   ],
   "source": [
    "n_epochs= 10\n",
    "batch_size = 150\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in  range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): # 60000/150 을 100번 반복해서 돈다.\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            # 이미지 사이즈로 생성\n",
    "            X_batch = X_batch.reshape((-1,n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "        print(epoch, 'Train accuracy : ', acc_train, 'Test accyract : ',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ICT01_02\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "cell <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718D9E5A88>\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718D9E5A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718D9E5A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718D9E5A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718D9E5A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "1.  Tensor(\"rnn/transpose_1:0\", shape=(?, 28, 128), dtype=float32)\n",
      "2.  Tensor(\"transpose:0\", shape=(28, ?, 128), dtype=float32)\n",
      "3.  Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-13-80be95619258>:33: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('./mnist/data/', one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "total_epoch = 10\n",
    "batch_size=128\n",
    "n_input=28\n",
    "n_step=28\n",
    "n_hidden=128\n",
    "n_class=10\n",
    "\n",
    "X=tf.placeholder(tf.float32, [None,n_step, n_input]) # 128x28x28\n",
    "Y= tf.placeholder(tf.float32, [None,n_class]) # 128x10\n",
    "W= tf.Variable(tf.random_normal([n_hidden, n_class])) # 128x10\n",
    "b= tf.Variable(tf.random_normal([n_class])) # 10\n",
    "# 28x128 사이즈의 가중치\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden) # neurons : 128:특징으로\n",
    "print('cell',cell) # => \n",
    "# cell 수 : 28\n",
    "# FFNN\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "print('1. ',outputs) # =>? x 28x128\n",
    "# outputs : 128x28x128, states : 128x128\n",
    "outputs = tf.transpose(outputs, [1,0,2]) # 28x128x128\n",
    "print('2. ',outputs) # => 28x?x128\n",
    "# cell로 판단하겠다. 한장에 128개의 셀이 있다 그것이 28장이있다.\n",
    "outputs = outputs[-1] # 맨마지막 셀: 128x128\n",
    "print('3. ',outputs) # => ?x128\n",
    "model = tf.matmul(outputs, W) + b # 128x128, 128x10, 10 => 128x10\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.562\n",
      "Epoch: 0002 Avg. cost = 0.236\n",
      "Epoch: 0003 Avg. cost = 0.179\n",
      "Epoch: 0004 Avg. cost = 0.148\n",
      "Epoch: 0005 Avg. cost = 0.140\n",
      "Epoch: 0006 Avg. cost = 0.125\n",
      "Epoch: 0007 Avg. cost = 0.111\n",
      "Epoch: 0008 Avg. cost = 0.116\n",
      "Epoch: 0009 Avg. cost = 0.099\n",
      "Epoch: 0010 Avg. cost = 0.098\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 60000/128\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(total_epoch): # 10\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 사이즈로 리세입\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        # _ : python이 계산한 마지막 결과가 저장되는것\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "    print(\"Epoch:\", \"%04d\" % (epoch +1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "print(\"최적화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 \n",
    "# 1. 테스트 데이를 이용하여 테스트 하는 회로를 구성하시요\n",
    "# 2. 3개의 셀을 갖는 multi_layer cell로 수정하시요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 1.103\n",
      "Epoch: 0002 Avg. cost = 0.519\n",
      "Epoch: 0003 Avg. cost = 0.395\n",
      "Epoch: 0004 Avg. cost = 0.319\n",
      "Epoch: 0005 Avg. cost = 0.273\n",
      "Epoch: 0006 Avg. cost = 0.221\n",
      "Epoch: 0007 Avg. cost = 0.211\n",
      "Epoch: 0008 Avg. cost = 0.196\n",
      "Epoch: 0009 Avg. cost = 0.155\n",
      "Epoch: 0010 Avg. cost = 0.140\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 테스트?\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 60000/128\n",
    "total_batch = int(mnist.test.num_examples/batch_size)\n",
    "for epoch in range(total_epoch): # 10\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.test.next_batch(batch_size)\n",
    "        # 이미지 사이즈로 리세입\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        # _ : python이 계산한 마지막 결과가 저장되는것\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "    print(\"Epoch:\", \"%04d\" % (epoch +1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "print(\"최적화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 3개의 셀을 갖는 multi_layer cell로 수정하시요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('./mnist/data/', one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "total_epoch = 10\n",
    "batch_size=128\n",
    "n_input=28\n",
    "n_step=28\n",
    "n_hidden=128\n",
    "n_class=10\n",
    "n_layers=3  # 3개의 멀티레이어 \n",
    "\n",
    "X=tf.placeholder(tf.float32, [None,n_step, n_input]) # 128x28x28\n",
    "Y= tf.placeholder(tf.float32, [None,n_class]) # 128x10\n",
    "W= tf.Variable(tf.random_normal([n_hidden, n_class])) # 128x10\n",
    "b= tf.Variable(tf.random_normal([n_class])) # 10\n",
    "\n",
    "# 3개의 셀로 멀티레이어 생성해도 output은 하나의 셀일 경유와 동일\n",
    "# state에서는 3개의 레이어마다 생성\n",
    "layers=[tf.contrib.rnn.BasicRNNCell(num_units=n_hidden, activation=tf.nn.relu) for layer in range(n_layers)]  \n",
    "\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8B4A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8B4A88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8B4A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171DB8B4A88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718DBB5708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718DBB5708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718DBB5708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001718DBB5708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB71F6C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB71F6C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB71F6C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000171DB71F6C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000017198FB5448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000017198FB5448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000017198FB5448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x0000017198FB5448>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs, [1,0,2]) \n",
    "\n",
    "outputs = outputs[-1] \n",
    "\n",
    "model = tf.matmul(outputs, W) + b # 128x128, 128x10, 10 => 128x10\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.0833\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "is_correct = tf.equal(tf.argmax(model,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels\n",
    "print('정확도 : ', sess.run(accuracy, feed_dict={X:test_xs, Y:test_ys}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규진언니"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"Variable:0\", shape=(128, 10), dtype=float32_ref) must be from the same graph as Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2dfa3f8ec05c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBasicRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmulti_layer_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2567\u001b[0m       \u001b[0mare\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2568\u001b[0m   \"\"\"\n\u001b[1;32m-> 2569\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2571\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only one of transpose_a and adjoint_a can be True.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6506\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6507\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6508\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6509\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6510\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   6133\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6134\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6135\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6136\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6137\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   6069\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6070\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001b[1;32m-> 6071\u001b[1;33m                      (item, original_item))\n\u001b[0m\u001b[0;32m   6072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"Variable:0\", shape=(128, 10), dtype=float32_ref) must be from the same graph as Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32)."
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "learning_rate = 0.001\n",
    "total_epoch = 10\n",
    "batch_size = 128\n",
    "n_input = 28\n",
    "n_step = 28\n",
    "n_hidden = 128\n",
    "n_class = 10\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input]) # 128X28X28\n",
    "Y = tf.placeholder(tf.float32, [None, n_class]) # 128X10\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class])) #128X10\n",
    "b = tf.Variable(tf.random_normal([n_class])) # 10\n",
    "\n",
    "n_layers = 3\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_hidden, activation=tf.nn.relu) for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "model = tf.matmul(outputs, W) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "outputs = tf.transpose(outputs, [1,0,2])\n",
    "outputs = outputs[-1]\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels\n",
    "print('정확도: ', sess.run(accuracy, feed_dict={X: test_xs, Y: test_ys}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "values231 = np.array([[[1],[2],[3]],[[2],[3],[4]]])\n",
    "print('입력데이터의 shape ', values231.shape) #2x3x1\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf_values231 = tf.constant(values231, dtype=tf.float32)\n",
    "\n",
    "# 가중치 : 1x100 4개가 있어야한다.\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(num_units = 100) # 뉴론 100\n",
    "\n",
    "# rnn 모델은 동일 : 망과 망을 연결할 때 (번역망 : 한글, 영어)\n",
    "# latent time 지연시간\n",
    "outputs, state = tf.nn.dynamic_rnn(cell=lstm_cell, dtype=tf.float32, inputs=tf_values231)\n",
    "# state : 2개가 나온다.\n",
    "print(state.c.shape) # 2x100\n",
    "print(state.h.shape) # 2x100\n",
    "print('rnn이 출력하는outputs의 의미 ', outputs.shape) # 2x3x100 => 데이터 2개 셀은 3개\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_run, state_run = sess.run([outputs, state])\n",
    "    print('output_run : ',output_run.shape)\n",
    "    print('state_run.c : ',state_run.c.shape)\n",
    "    print('state_run.h : ',state_run.h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "values = tf.constant(np.array([[[1],[2],[3]],[[2],[3],[4]]]), dtype=tf.float32)\n",
    "lstm_cell_fw = tf.contrib.rnn.LSTMCell(100)\n",
    "lstm_cell_bw = tf.contrib.rnn.LSTMCell(100)\n",
    "# 양방향 LSTM\n",
    "# Multi cell : 셀에서\n",
    "(output_fw, output_bw), (output_state_fw, output_state_bw) = tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_cell_fw, cell_bw = lstm_cell_bw,inputs=values, dtype=tf.float32)\n",
    "\n",
    "print(output_fw.shape)\n",
    "print(output_bw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enbedding\n",
    "import pprint\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "pp = pprint.PrettyPrinter(indent = 4) # 형태그대로?\n",
    "sess = tf.InteractiveSession()\n",
    "h = [1,0,0,0] # 단어를 원핫인코딩 : 수치화\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]\n",
    "\n",
    "# 변수공유를 위해 지정\n",
    "with tf.variable_scope('five_sequences') as scope:\n",
    "    hidden_size = 2\n",
    "    # 4 -> 2 개의 특징으로 vector화된다.\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)\n",
    "    x_data = np.array([[h,e,l,l,o]], dtype=np.float32)\n",
    "    print(x_data.shape) # 1x5x4  : 데이터 함개 => 3차원으로\n",
    "    pp.pprint(x_data)\n",
    "    # cell의 개수 : 5개\n",
    "    # cell당 입력데이터 : 4개\n",
    "    # cell당 가중치 : 4x2\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell, x_data,dtype =tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())\n",
    "    print('\\n',outputs.shape,'\\n') # 1x5x2\n",
    "    print(states.shape,'\\n') # 1x2\n",
    "    pp.pprint(states.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "char_arr = ['a','b','c','d','e',',f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "# a:0 번호를 키로\n",
    "dic_len = len(num_dic)\n",
    "# rule base => 자동툴 => 가중치만 이용하면 \n",
    "seq_data = ['word', 'wood','deep','dive','cold','cool','load','love','kiss','kind']\n",
    "# 10x3\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26x26행렬\n",
    "# 1000000000000000000000000\n",
    "# 0100000000000000000000000\n",
    "# 0010000000000000000000000 ...\n",
    "def make_batch(seq_data): # 자동으로 문자를 원핫 인코딩\n",
    "    input_batch = []\n",
    "    target_batch=[]\n",
    "    for seq in seq_data: # word\n",
    "        input = [num_dic[n] for n in seq[:-1]] # w=22, o=14, r=17\n",
    "        target = num_dic[seq[-1]] # d=3\n",
    "        input_batch.append(np.eye(dic_len)[input]) # 원핫 인코딩\n",
    "        target_batch.append(target)\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 30\n",
    "n_step=3\n",
    "n_input = n_class=dic_len # 26개\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input]) # 10x3x26\n",
    "Y = tf.placeholder(tf.int32, [None]) # 10x26\n",
    "# FFNN\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class])) # 128x26\n",
    "b = tf.Variable(tf.random_normal([n_class])) # 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171C206FC88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171C206FC88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171C206FC88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x00000171C206FC88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE5C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE5C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE5C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE5C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE8C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x00000171E0ADE8C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden) # 특성수 128\n",
    "# 계산한 양이 많아서 50%만 남기고 계산\n",
    "# 과적합 방지 -> dropout\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5,seed=10)\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# 2레이어로 구성된 멀티셀\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X,dtype=tf.float32)\n",
    "\n",
    "# outputs : 10x3x128\n",
    "# states : 10x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.transpose(outputs, [1,0,2]) # 3x10x128 \n",
    "outputs = outputs[-1] # 맨뒤에쓸 셀 10x1218\n",
    "model = tf.matmul(outputs, W)+b # 비선형 회귀방식\n",
    "# 분류\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0001 cost = 3.554584\n",
      "Epoch : 0002 cost = 2.609149\n",
      "Epoch : 0003 cost = 1.441095\n",
      "Epoch : 0004 cost = 1.579632\n",
      "Epoch : 0005 cost = 0.680771\n",
      "Epoch : 0006 cost = 0.897215\n",
      "Epoch : 0007 cost = 0.593994\n",
      "Epoch : 0008 cost = 0.424144\n",
      "Epoch : 0009 cost = 0.325358\n",
      "Epoch : 0010 cost = 0.234904\n",
      "Epoch : 0011 cost = 0.199243\n",
      "Epoch : 0012 cost = 0.304904\n",
      "Epoch : 0013 cost = 0.255864\n",
      "Epoch : 0014 cost = 0.165813\n",
      "Epoch : 0015 cost = 0.082868\n",
      "Epoch : 0016 cost = 0.115473\n",
      "Epoch : 0017 cost = 0.116674\n",
      "Epoch : 0018 cost = 0.103213\n",
      "Epoch : 0019 cost = 0.063181\n",
      "Epoch : 0020 cost = 0.080963\n",
      "Epoch : 0021 cost = 0.104196\n",
      "Epoch : 0022 cost = 0.016710\n",
      "Epoch : 0023 cost = 0.053694\n",
      "Epoch : 0024 cost = 0.044977\n",
      "Epoch : 0025 cost = 0.007708\n",
      "Epoch : 0026 cost = 0.002861\n",
      "Epoch : 0027 cost = 0.102131\n",
      "Epoch : 0028 cost = 0.036725\n",
      "Epoch : 0029 cost = 0.020556\n",
      "Epoch : 0030 cost = 0.001445\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "input_batch , target_batch = make_batch(seq_data) # 단어데이터\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost], feed_dict={X:input_batch, Y:target_batch})\n",
    "    print('Epoch : %04d'%(epoch+1), 'cost = {:.6f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.cast(tf.argmax(model,1), tf.int32)\n",
    "prediction_check = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "predict, accuracy_val = sess.run([prediction, accuracy], feed_dict={X:input_batch, Y:target_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 predict한 결과출력\n",
    "# accuracy 출력\n",
    "# 입력단어와 예측단어 결과를 나란히 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  3 15  4  3 11  3  4 18  3]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(predict)\n",
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력값 :  ['wor ', 'woo ', 'dee ', 'div ', 'col ', 'coo ', 'loa ', 'lov ', 'kis ', 'kin ']\n",
      "예측값 :  ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "predict_words = []\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_words.append(val[:3] + last_char)\n",
    "print('입력값 : ',[w[:3] + ' ' for w in seq_data])\n",
    "print('예측값 : ',predict_words)\n",
    "print('정확도 : ',accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
